### LORA Fine-tuned Bloom1b7 for Question Answering with SQuAD v2
This repository contains the code and resources for fine-tuning a Bloom 1b7 model with LoRA (Low-Rank Adaptation) for question answering using the Stanford Question Answering Dataset (SQuAD) v2.

###Overview

Bloom 1b7 is a large language model (LLM) pre-trained on a massive dataset of text and code. LoRA is a technique that allows for efficient adaptation of large models to specific tasks using a small amount of additional parameters. In this project, we fine-tune the Bloom 1b7 model with LoRA for the task of extractive question answering on SQuAD v2.



